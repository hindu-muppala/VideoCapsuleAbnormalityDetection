{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10779893,"sourceType":"datasetVersion","datasetId":6688727},{"sourceId":10841834,"sourceType":"datasetVersion","datasetId":6733049}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torchvision.models as models\nimport torch\nfrom torchvision.transforms import v2\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, Sampler\nimport torchvision.datasets as datasets\n\n# import os\nimport matplotlib.pyplot as plt\n# import matplotlib.image as mpimg\n# from PIL import Image\nimport numpy as np\n\n\nimport random\nimport numpy as np\nfrom sklearn.metrics import f1_score, balanced_accuracy_score, roc_auc_score\nfrom sklearn.metrics import classification_report\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:50:15.554175Z","iopub.execute_input":"2025-04-02T10:50:15.554370Z","iopub.status.idle":"2025-04-02T10:50:25.583967Z","shell.execute_reply.started":"2025-04-02T10:50:15.554350Z","shell.execute_reply":"2025-04-02T10:50:25.583324Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"class TrainingDataset(Dataset):\n    \n    def __init__(self, dataset, augmentation ):\n        self.dataset = dataset\n\n    def __len__(self):\n        return len(dataset)\n\n    def __getitem__(self, idx):\n        image_path, label = self.dataset.samples[idx]  \n        image = self.dataset.loader(image_path) \n        image = augmentation(image)\n\n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:50:34.785523Z","iopub.execute_input":"2025-04-02T10:50:34.785805Z","iopub.status.idle":"2025-04-02T10:50:34.790167Z","shell.execute_reply.started":"2025-04-02T10:50:34.785783Z","shell.execute_reply":"2025-04-02T10:50:34.789410Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"**Augumentation**\n","metadata":{}},{"cell_type":"code","source":"augmentation = transforms.Compose([\n      \n    transforms.Resize((224, 224)),\n\n    transforms.RandomRotation(degrees=(0, 10)), \n    \n    transforms.RandomApply([transforms.RandomHorizontalFlip()], p=0.5),\n\n    transforms.RandomApply([transforms.RandomVerticalFlip()], p=0.5),\n\n    transforms.ToTensor()\n    \n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:50:38.369525Z","iopub.execute_input":"2025-04-02T10:50:38.369809Z","iopub.status.idle":"2025-04-02T10:50:38.374525Z","shell.execute_reply.started":"2025-04-02T10:50:38.369788Z","shell.execute_reply":"2025-04-02T10:50:38.373724Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class ResNetTransformerClassifier(nn.Module):\n    \n    def __init__(self, num_classes=4, d_model=2048, num_heads=8, num_layers=2):\n        \n        super(ResNetTransformerClassifier, self).__init__()\n        self.resnet = models.resnet50(pretrained=True)\n        self.resnet.fc = nn.Identity()  \n  \n        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads,  batch_first=True )\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n        \n        self.fc = nn.Linear(d_model, num_classes)\n\n    def forward(self, x):\n        \n        x = self.resnet(x)  \n        x = x.unsqueeze(1)  \n        \n        x = self.transformer(x)  \n        x = x.squeeze(1)\n        \n        return self.fc(x) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:50:42.651731Z","iopub.execute_input":"2025-04-02T10:50:42.652030Z","iopub.status.idle":"2025-04-02T10:50:42.657411Z","shell.execute_reply.started":"2025-04-02T10:50:42.651988Z","shell.execute_reply":"2025-04-02T10:50:42.656589Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"dataset_path = '/kaggle/input/trining-dataset/training'\nvalidationDataset_path = '/kaggle/input/validation/validating'\n\ntraining_dataset = datasets.ImageFolder(root=dataset_path)\nvalidation_dataset = datasets.ImageFolder(root=validationDataset_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:51:07.560853Z","iopub.execute_input":"2025-04-02T10:51:07.561221Z","iopub.status.idle":"2025-04-02T10:53:01.977478Z","shell.execute_reply.started":"2025-04-02T10:51:07.561192Z","shell.execute_reply":"2025-04-02T10:53:01.976766Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"**DATA STATISTICS**","metadata":{}},{"cell_type":"code","source":"len(training_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:53:11.301172Z","iopub.execute_input":"2025-04-02T10:53:11.301460Z","iopub.status.idle":"2025-04-02T10:53:11.307149Z","shell.execute_reply.started":"2025-04-02T10:53:11.301441Z","shell.execute_reply":"2025-04-02T10:53:11.306326Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"33673"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"len(validation_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:53:14.449271Z","iopub.execute_input":"2025-04-02T10:53:14.449553Z","iopub.status.idle":"2025-04-02T10:53:14.454521Z","shell.execute_reply.started":"2025-04-02T10:53:14.449533Z","shell.execute_reply":"2025-04-02T10:53:14.453718Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"14439"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"def get_statistics(dataset):\n    class_counts = {'A':0, 'P':0, 'N':0, 'E':0}\n    for _, label in dataset.samples:\n        class_counts[dataset.classes[label]] += 1\n\n    print(\"the statistics ---\")\n\n    print(\"Total number --\")\n    \n    for key, value in enumerate(class_counts):\n        print(value, ' ', class_counts[value])\n\n    print(\"Now, let go to the percentage :::\")\n\n    len_ = len(dataset)\n\n    for key, value in enumerate(class_counts):\n        print(class_counts[value]/len_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:53:17.794005Z","iopub.execute_input":"2025-04-02T10:53:17.794304Z","iopub.status.idle":"2025-04-02T10:53:17.798984Z","shell.execute_reply.started":"2025-04-02T10:53:17.794283Z","shell.execute_reply":"2025-04-02T10:53:17.798335Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"get_statistics(training_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:53:20.832760Z","iopub.execute_input":"2025-04-02T10:53:20.833088Z","iopub.status.idle":"2025-04-02T10:53:20.844426Z","shell.execute_reply.started":"2025-04-02T10:53:20.833053Z","shell.execute_reply":"2025-04-02T10:53:20.843637Z"}},"outputs":[{"name":"stdout","text":"the statistics ---\nTotal number --\nA   1154\nP   1162\nN   28663\nE   2694\nNow, let go to the percentage :::\n0.03427078074421643\n0.03450835981350043\n0.8512161078608974\n0.08000475158138567\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"**FROM STATISTICS - UNDERSAMPLING CONCLUSION**\n\n- concluded the undersample percentage of the erosion will be 0.1","metadata":{}},{"cell_type":"code","source":"target_class = \"N\"  \npercentage = 0.1\n\nclass_to_idx = training_dataset.class_to_idx\ntarget_class_idx = class_to_idx[target_class]\n\nclass_indices = [\n    \n    i for i, (_, label) in enumerate(training_dataset.samples) \n    if label == target_class_idx\n    \n]\n\nnum_samples = int(len(class_indices) * percentage)\nselected_indices = random.sample(class_indices, num_samples)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:54:13.914884Z","iopub.execute_input":"2025-04-02T10:54:13.915227Z","iopub.status.idle":"2025-04-02T10:54:13.925265Z","shell.execute_reply.started":"2025-04-02T10:54:13.915201Z","shell.execute_reply":"2025-04-02T10:54:13.924604Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"**loading the dataset**","metadata":{}},{"cell_type":"markdown","source":"**NOW, LET DEFINE THE INDEXES**","metadata":{}},{"cell_type":"code","source":"# finding first, last indexex, + middle indexes + last indexes\n\nlabels = np.array([label for _, label in training_dataset.samples])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:53:40.691297Z","iopub.execute_input":"2025-04-02T10:53:40.691565Z","iopub.status.idle":"2025-04-02T10:53:40.698617Z","shell.execute_reply.started":"2025-04-02T10:53:40.691545Z","shell.execute_reply":"2025-04-02T10:53:40.697801Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def find_class_indices(dataset, class_name):\n    \"\"\"Find first and last index of a class in ImageFolder dataset.\"\"\"\n    class_idx = dataset.class_to_idx[class_name]\n    indices = np.where(labels == class_idx)[0]   \n    \n    if len(indices) == 0:\n        return None, None  # Class not found\n    \n    return indices[0], indices[-1]  # First and last occurrence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:53:47.185405Z","iopub.execute_input":"2025-04-02T10:53:47.185687Z","iopub.status.idle":"2025-04-02T10:53:47.189516Z","shell.execute_reply.started":"2025-04-02T10:53:47.185666Z","shell.execute_reply":"2025-04-02T10:53:47.188837Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"first_idx_P, last_idx_P = find_class_indices(training_dataset, 'P')\nfirst_idx_A, last_idx_A = find_class_indices(training_dataset, 'A')\nfirst_idx_E, last_idx_E = find_class_indices(training_dataset, 'E')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:53:51.268299Z","iopub.execute_input":"2025-04-02T10:53:51.268583Z","iopub.status.idle":"2025-04-02T10:53:51.276350Z","shell.execute_reply.started":"2025-04-02T10:53:51.268563Z","shell.execute_reply":"2025-04-02T10:53:51.275609Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"last_idx_A , first_idx_E","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:53:54.424153Z","iopub.execute_input":"2025-04-02T10:53:54.424476Z","iopub.status.idle":"2025-04-02T10:53:54.430295Z","shell.execute_reply.started":"2025-04-02T10:53:54.424453Z","shell.execute_reply":"2025-04-02T10:53:54.429382Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(1153, 1154)"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# CONCUDED EXCLUSIVE INTERVALS\nADD_a = [ x for x in range(first_idx_A, last_idx_A +1 )]\nADD_p =  [ x for x in range(first_idx_P, last_idx_P +1 )]\nADD_e =  [ x for x in range(first_idx_E, last_idx_E +1 )]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:53:57.400741Z","iopub.execute_input":"2025-04-02T10:53:57.401054Z","iopub.status.idle":"2025-04-02T10:53:57.405320Z","shell.execute_reply.started":"2025-04-02T10:53:57.401030Z","shell.execute_reply":"2025-04-02T10:53:57.404548Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"final_indexes = ADD_a + ADD_p + ADD_e  + selected_indices ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:54:20.701515Z","iopub.execute_input":"2025-04-02T10:54:20.701826Z","iopub.status.idle":"2025-04-02T10:54:20.705533Z","shell.execute_reply.started":"2025-04-02T10:54:20.701801Z","shell.execute_reply":"2025-04-02T10:54:20.704841Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"len(final_indexes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:54:25.061859Z","iopub.execute_input":"2025-04-02T10:54:25.062199Z","iopub.status.idle":"2025-04-02T10:54:25.067156Z","shell.execute_reply.started":"2025-04-02T10:54:25.062172Z","shell.execute_reply":"2025-04-02T10:54:25.066236Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"7876"},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"**DEFINING THE SAMPLER**","metadata":{}},{"cell_type":"code","source":"train_dataset = TrainingDataset(training_dataset, augmentation)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T09:44:13.129692Z","iopub.execute_input":"2025-04-01T09:44:13.129984Z","iopub.status.idle":"2025-04-01T09:44:13.133371Z","shell.execute_reply.started":"2025-04-01T09:44:13.129960Z","shell.execute_reply":"2025-04-01T09:44:13.132556Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"class UnderSampler(Sampler):\n    \n    def __init__(self, indices):\n        self.indices = indices\n\n    def __iter__(self):\n        return iter(random.sample(self.indices, len(self.indices)))  # Returns shuffled indices\n\n    def __len__(self):\n        return len(self.indices)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T09:44:19.068987Z","iopub.execute_input":"2025-04-01T09:44:19.069324Z","iopub.status.idle":"2025-04-01T09:44:19.073551Z","shell.execute_reply.started":"2025-04-01T09:44:19.069293Z","shell.execute_reply":"2025-04-01T09:44:19.072670Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=64, sampler=UnderSampler(final_indexes)\n                         \n                     )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T11:51:56.755118Z","iopub.execute_input":"2025-04-01T11:51:56.755447Z","iopub.status.idle":"2025-04-01T11:51:56.759229Z","shell.execute_reply.started":"2025-04-01T11:51:56.755419Z","shell.execute_reply":"2025-04-01T11:51:56.758338Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# for image, label in train_loader:\n#     print(label)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T03:34:22.480998Z","iopub.execute_input":"2025-04-01T03:34:22.481392Z","iopub.status.idle":"2025-04-01T03:34:22.485516Z","shell.execute_reply.started":"2025-04-01T03:34:22.481363Z","shell.execute_reply":"2025-04-01T03:34:22.484433Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class ValidationDataset(Dataset):\n    \n    def __init__(self, dataset, augmentation):\n        self.dataset = dataset\n        self.augmentation = augmentation\n        \n    def __len__(self):\n        return 7876\n\n    def __getitem__(self, idx):\n        \n        image_path, label = validation_dataset.samples[idx]\n        image =   validation_dataset.loader(image_path) \n\n        image = self.augmentation(image)\n\n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T09:44:34.972142Z","iopub.execute_input":"2025-04-01T09:44:34.972467Z","iopub.status.idle":"2025-04-01T09:44:34.977012Z","shell.execute_reply.started":"2025-04-01T09:44:34.972445Z","shell.execute_reply":"2025-04-01T09:44:34.976227Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"**loading validation dataset**","metadata":{}},{"cell_type":"code","source":"validation_dataset2 = ValidationDataset(validation_dataset, augmentation)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T09:44:46.304764Z","iopub.execute_input":"2025-04-01T09:44:46.305053Z","iopub.status.idle":"2025-04-01T09:44:46.308704Z","shell.execute_reply.started":"2025-04-01T09:44:46.305030Z","shell.execute_reply":"2025-04-01T09:44:46.307896Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"valid_loader = DataLoader( validation_dataset2, batch_size=128 )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T09:44:48.729297Z","iopub.execute_input":"2025-04-01T09:44:48.729613Z","iopub.status.idle":"2025-04-01T09:44:48.733489Z","shell.execute_reply.started":"2025-04-01T09:44:48.729591Z","shell.execute_reply":"2025-04-01T09:44:48.732569Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"model = ResNetTransformerClassifier()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T11:52:02.236212Z","iopub.execute_input":"2025-04-01T11:52:02.236538Z","iopub.status.idle":"2025-04-01T11:52:03.074588Z","shell.execute_reply.started":"2025-04-01T11:52:02.236511Z","shell.execute_reply":"2025-04-01T11:52:03.073912Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"trainable_params = list(model.transformer.parameters()) + list(model.fc.parameters())\n\noptimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-1)\n\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T11:52:18.247224Z","iopub.execute_input":"2025-04-01T11:52:18.247509Z","iopub.status.idle":"2025-04-01T11:52:18.253606Z","shell.execute_reply.started":"2025-04-01T11:52:18.247487Z","shell.execute_reply":"2025-04-01T11:52:18.252864Z"}},"outputs":[],"execution_count":49},{"cell_type":"markdown","source":"**testing certieria**","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T11:52:21.669328Z","iopub.execute_input":"2025-04-01T11:52:21.669631Z","iopub.status.idle":"2025-04-01T11:52:21.673489Z","shell.execute_reply.started":"2025-04-01T11:52:21.669606Z","shell.execute_reply":"2025-04-01T11:52:21.672593Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"\nnum_epochs = 80\n\npatience = 10\nbest_metric = -np.inf  \n\nepochs_no_improve = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T11:52:32.423310Z","iopub.execute_input":"2025-04-01T11:52:32.423596Z","iopub.status.idle":"2025-04-01T11:52:32.427489Z","shell.execute_reply.started":"2025-04-01T11:52:32.423573Z","shell.execute_reply":"2025-04-01T11:52:32.426615Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    \n    model.train()\n    \n    running_loss = 0.0\n    \n    for images, labels in train_loader:\n        \n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        outputs = model(images)\n\n        loss = criterion(outputs, labels).to(device)\n        \n        loss.backward()\n\n  #      print(loss)\n        \n        optimizer.step()\n        \n        running_loss += loss.item()\n\n    # calculate the loss\n\n    scheduler.step()\n\n    preds_ = []\n    real_ = []\n    \n    with torch.no_grad():\n    \n        for images, labels in train_loader:\n        \n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n            preds_.extend(preds.cpu().numpy()) \n            real_.extend(labels.cpu().numpy())\n\n        no_trues= {0:0, 1:0, 2:0, 3:0}\n        no_r_t = {0:0, 1:0, 2:0, 3:0}\n        \n        for p1, t1 in zip(preds_, real_):\n\n            if p1 == t1 :\n                no_trues[t1] += 1\n                \n            no_r_t[t1] += 1\n            \n    print(no_trues)\n    print(no_r_t)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T11:52:35.424750Z","iopub.execute_input":"2025-04-01T11:52:35.425039Z","iopub.status.idle":"2025-04-01T12:35:11.110344Z","shell.execute_reply.started":"2025-04-01T11:52:35.425015Z","shell.execute_reply":"2025-04-01T12:35:11.109100Z"}},"outputs":[{"name":"stdout","text":"{0: 0, 1: 2672, 2: 28, 3: 0}\n{0: 1154, 1: 2694, 2: 2006, 3: 1162}\n{0: 6, 1: 2254, 2: 1666, 3: 43}\n{0: 1154, 1: 2694, 2: 2006, 3: 1162}\n{0: 0, 1: 2480, 2: 1609, 3: 0}\n{0: 1154, 1: 2694, 2: 2006, 3: 1162}\n{0: 0, 1: 2485, 2: 1657, 3: 0}\n{0: 1154, 1: 2694, 2: 2006, 3: 1162}\n{0: 0, 1: 2503, 2: 1631, 3: 0}\n{0: 1154, 1: 2694, 2: 2006, 3: 1162}\n{0: 0, 1: 2525, 2: 1630, 3: 0}\n{0: 1154, 1: 2694, 2: 2006, 3: 1162}\n{0: 0, 1: 2516, 2: 1645, 3: 0}\n{0: 1154, 1: 2694, 2: 2006, 3: 1162}\n{0: 0, 1: 2518, 2: 1646, 3: 0}\n{0: 1154, 1: 2694, 2: 2006, 3: 1162}\n{0: 0, 1: 2523, 2: 1641, 3: 0}\n{0: 1154, 1: 2694, 2: 2006, 3: 1162}\n{0: 0, 1: 2521, 2: 1650, 3: 0}\n{0: 1154, 1: 2694, 2: 2006, 3: 1162}\n{0: 0, 1: 2515, 2: 1648, 3: 0}\n{0: 1154, 1: 2694, 2: 2006, 3: 1162}\n{0: 0, 1: 2514, 2: 1647, 3: 0}\n{0: 1154, 1: 2694, 2: 2006, 3: 1162}\n{0: 0, 1: 2518, 2: 1653, 3: 0}\n{0: 1154, 1: 2694, 2: 2006, 3: 1162}\n{0: 0, 1: 2518, 2: 1650, 3: 0}\n{0: 1154, 1: 2694, 2: 2006, 3: 1162}\n{0: 0, 1: 2517, 2: 1642, 3: 0}\n{0: 1154, 1: 2694, 2: 2006, 3: 1162}\n{0: 0, 1: 2518, 2: 1656, 3: 0}\n{0: 1154, 1: 2694, 2: 2006, 3: 1162}\n{0: 0, 1: 2511, 2: 1648, 3: 0}\n{0: 1154, 1: 2694, 2: 2006, 3: 1162}\n{0: 0, 1: 2513, 2: 1654, 3: 0}\n{0: 1154, 1: 2694, 2: 2006, 3: 1162}\n{0: 0, 1: 2517, 2: 1657, 3: 0}\n{0: 1154, 1: 2694, 2: 2006, 3: 1162}\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-52-0c7fa49ef1d8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-538bc9ea1b98>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3513\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3515\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3517\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mID\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_open_core\u001b[0;34m(fp, filename, prefix, formats)\u001b[0m\n\u001b[1;32m   3496\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3497\u001b[0m                 \u001b[0mfactory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOPEN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3498\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0maccept\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0maccept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3499\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3500\u001b[0m                     \u001b[0mwarning_messages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/JpegImagePlugin.py\u001b[0m in \u001b[0;36m_accept\u001b[0;34m(prefix)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_accept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m     \u001b[0;31m# Magic number was taken from https://en.wikipedia.org/wiki/JPEG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"\\xFF\\xD8\\xFF\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":52},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# import torchvision.models as models\n\n# # Load a pretrained ResNet model\n# resnet = models.resnet50(pretrained=True)\n\n# # Remove the final fully connected layer\n# resnet.fc = nn.Identity()\n\n# # Forward pass through modified ResNet\n# x = torch.randn(1, 3, 224, 224)  # Example input\n# features = resnet(x)\n\n# print(features.shape)  # Output feature shape instead of class scores\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T07:50:48.883402Z","iopub.execute_input":"2025-04-01T07:50:48.883738Z","iopub.status.idle":"2025-04-01T07:50:48.888120Z","shell.execute_reply.started":"2025-04-01T07:50:48.883711Z","shell.execute_reply":"2025-04-01T07:50:48.886999Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}